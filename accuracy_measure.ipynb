{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "link='shuffled_preprocessed_data.csv'\n",
    "\n",
    "input1 = open(link, 'r')\n",
    "\n",
    "lines = itertools.islice(input1,1,None)\n",
    "reader = csv.reader(lines)\n",
    "\n",
    "full_len = len(list(reader))\n",
    "thres = int((full_len*3)/4)\n",
    "\n",
    "with open(link, newline='', encoding='utf8') as f:\n",
    "    lines = itertools.islice(f,1+thres,None)\n",
    "    reader = csv.reader(lines)\n",
    "    \n",
    "    cnt={}\n",
    "    for row in reader:\n",
    "        # Including only tags which are not empty\n",
    "        for i in range(6,len(row)):\n",
    "                if(row[i]!=''):\n",
    "                    cnt[row[i]]=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'9 11': 1, 'Prisonplanet': 1, 'WW3': 1, 'Nuclear': 1, 'Obamacare': 1, 'CIA': 1, 'MSM': 1, 'CPS': 1, 'Alternative Media': 1, 'War': 1, 'Benghazi': 1, 'Police State': 1, 'Putin': 1, 'HillaryForPrison': 1, 'NSA': 1, 'Inauguration': 1, 'Hillary': 1, 'NATO': 1, 'Fact': 1, 'News': 2, 'NWO': 1, 'Infowars': 1, 'Martial Law': 1, 'RealAlexJones': 1, 'Snowden': 1, 'IRS': 1, 'Elections': 1, 'Wikileaks': 1, 'EU': 1, 'Russia': 1, 'Al Qaeda': 1, 'John Kerry': 1, 'False': 1, 'Trump': 1, 'Hack': 1, 'Hillary Clinton': 1, 'Alex Jones': 1, 'Nightly News': 1, 'Lies': 1, 'Donald': 1, 'UN': 1, 'Election': 1, 'Drones': 1, 'Check': 1, 'Corden': 2, 'letterman': 1, 'The Late Show': 1, 'Colbert': 2, 'celeb': 2, 'comedian': 2, 'impressions': 2, 'funny': 2, 'CBS': 2, 'skits': 1, 'david letterman': 1, 'Important': 2, 'Late Show': 1, 'hollywood': 2, 'comedy': 2, 'James Corden': 2, 'celebrities': 2, 'funny video': 2, 'Late Late Show': 2, 'bit': 1, 'late night': 2, 'joke': 2, 'celebrity': 2, 'talk show': 1, 'funny videos': 2, 'jokes': 2, 'The Late Late Show': 2, 'Stephen Colbert': 2, 'monologue': 2, 'CNN': 1, 'default': 1, 'CNN TV': 1, 'CNN Newsroom': 1, 'wooden educational toys': 1, 'YouTube Editor': 1, 'street vehicle toys': 1, 'cut with paper': 1, '10': 1, 'life': 1, 'wood': 1, 'life hacks': 1, 'paper': 1, 'experiment': 1, 'hack': 1, 'TRIKCS': 1, 'angle grinder': 1, 'cut paper': 1, 'carpool': 1, 'late night show': 1, 'karaoke': 1, 'Harpursville': 1, 'giraffe cam': 1, 'Park': 1, 'Zoo': 1, 'Giraffe': 1, 'Adventure': 1, 'Animal': 1, 'New York': 1, 'Animal Adventure': 1, 'African Elephant Animal ': 1, 'Safari Industry ': 1, 'Djuma Game Reserve Location ': 1, 'Livestream Website ': 1, 'Kruger National Park Protected Site ': 1, 'Leopard Animal ': 1, 'Lion Animal ': 1, 'Wildlife Film Subject ': 1, 'Giraffe Animal ': 1}\n"
     ]
    }
   ],
   "source": [
    "# Dictionary of occurrences of each tag in the data set\n",
    "with open(link, newline='', encoding='utf8') as f:\n",
    "    lines = itertools.islice(f,1+thres,None)\n",
    "    reader = csv.reader(lines)\n",
    "    \n",
    "    for row in reader:\n",
    "            for i in range(6,len(row)):\n",
    "                if(row[i]!=''):\n",
    "                    cnt[row[i]]+=1\n",
    "\n",
    "    print(cnt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "link='predicted_data.csv'\n",
    "\n",
    "with open(link, newline='', encoding='utf8') as f:\n",
    "    lines = itertools.islice(f,1,None)\n",
    "    reader = csv.reader(lines)\n",
    "    \n",
    "    cnt_pred={}\n",
    "    for row in reader:\n",
    "        # Including only tags which are not empty\n",
    "        for i in range(6,len(row)):\n",
    "                if(row[i]!=''):\n",
    "                    cnt_pred[row[i]]=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'YouTube Editor': 1, 'street vehicle toys': 1, 'wooden educational toys': 1, 'CNN': 1, 'CNN Newsroom': 1, 'CNN TV': 1, 'News': 1, 'default': 1, 'African Elephant Animal ': 2, 'Djuma Game Reserve Location ': 2, 'Giraffe Animal ': 2, 'Kruger National Park Protected Site ': 2, 'Leopard Animal ': 2, 'Lion Animal ': 2, 'Livestream Website ': 2, 'Safari Industry ': 2, 'Wildlife Film Subject ': 2}\n"
     ]
    }
   ],
   "source": [
    "# Dictionary of occurrences of each tag in the data set\n",
    "with open(link, newline='', encoding='utf8') as f:\n",
    "    lines = itertools.islice(f,1,None)\n",
    "    reader = csv.reader(lines)\n",
    "    \n",
    "    for row in reader:\n",
    "            #print(row[6])\n",
    "            for i in range(6,len(row)):\n",
    "                if(row[i]!=''):\n",
    "                    cnt_pred[row[i]]+=1\n",
    "\n",
    "    print(cnt_pred)\n",
    "    #print('YouTube Editor' in cnt_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['Label', 'Actual Number of Videos', 'Predicted Number of Videos'], ['YouTube Editor', 1, 1], ['street vehicle toys', 1, 1], ['wooden educational toys', 1, 1], ['CNN', 1, 1], ['CNN Newsroom', 1, 1], ['CNN TV', 1, 1], ['News', 2, 1], ['default', 1, 1], ['African Elephant Animal ', 1, 2], ['Djuma Game Reserve Location ', 1, 2], ['Giraffe Animal ', 1, 2], ['Kruger National Park Protected Site ', 1, 2], ['Leopard Animal ', 1, 2], ['Lion Animal ', 1, 2], ['Livestream Website ', 1, 2], ['Safari Industry ', 1, 2], ['Wildlife Film Subject ', 1, 2], ['African Elephant Animal ', 1, 2], ['Djuma Game Reserve Location ', 1, 2], ['Giraffe Animal ', 1, 2], ['Kruger National Park Protected Site ', 1, 2], ['Leopard Animal ', 1, 2], ['Lion Animal ', 1, 2], ['Livestream Website ', 1, 2], ['Safari Industry ', 1, 2], ['Wildlife Film Subject ', 1, 2]]\n"
     ]
    }
   ],
   "source": [
    "with open(link, newline='', encoding='utf8') as f:\n",
    "    lines = itertools.islice(f,1,None)\n",
    "    reader = csv.reader(lines)\n",
    "    \n",
    "    # Header\n",
    "    list1=['Label', 'Actual Number of Videos', 'Predicted Number of Videos']\n",
    "    tot_list=[]\n",
    "    tot_list.append(list1)\n",
    "    \n",
    "    for row in reader:\n",
    "            # List of label, actual number of videos and predicted number of videos\n",
    "            for i in range(6,len(row)):\n",
    "                if(row[i]!=''):\n",
    "                    if(row[i] in cnt):\n",
    "                        list1=[row[i],cnt[row[i]],cnt_pred[row[i]]]\n",
    "                        tot_list.append(list1)\n",
    "                    else:\n",
    "                        list1=[row[i],0,cnt_pred[row[i]]]\n",
    "                        tot_list.append(list1)\n",
    "\n",
    "    print(tot_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Writing to file the accuracy data\n",
    "\n",
    "write_link='accuracy_data.csv'\n",
    "\n",
    "with open(write_link, 'w', newline='') as f:\n",
    "    writer = csv.writer(f)\n",
    "    writer.writerows(tot_list)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
